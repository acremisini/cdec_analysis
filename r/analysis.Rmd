---
title: "analysis"
author: "Andres Cremisini"
date: "March 26, 2019"
output: html_document
---

Specify data locations
```{r}
train.path = "../python/data/WDEC_train.csv"
test.path = "../python/data/WDEC_test.csv"
```

Load and prepare data
```{r}
library(caret)
library(DMwR)
set.seed(123)

# read data to csv
train = read.csv(file=train.path, header=TRUE, sep=",")
test = read.csv(file=test.path, header=TRUE, sep=",")

# clean
train = na.omit(train)
test = na.omit(test)

# add interaction term
train$interaction1 = (train$word2vec.similarity)*(train$lemma.overlap+.5)*train$sts
test$interaction1 = (test$word2vec.similarity)*(test$lemma.overlap+.5)*test$sts

# make dependent variable a factor
train$Class = as.factor(train$coreferent)
test$Class = as.factor(test$coreferent)

# change levels from 0,1 to False,True
levels(train$Class) = c('False', 'True')
levels(test$Class) = c('False', 'True')

# remove old response variable
train = subset(train, select=-c(coreferent))
test = subset(test, select=-c(coreferent))

# store response for convenience
train.Y=train$Class
test.Y=test$Class

# under and over sample
train.down_sample = downSample(x = train[, -ncol(train)],
                        y = train$Class)
train.smote <- SMOTE(Class ~ ., data  = train)   


```
Explore data
```{r}
plot(test$Class,(test$word2vec.similarity)*(test$lemma.overlap+.5)*test$sts)
```


Vanilla Random Forest
```{r}
library(caret)
library(pROC)
library(DMwR)
set.seed(123)

fit.RF = train(
               Class ~., # define the model
               data = train, # data
               method = "adaboost", # rf
               metric = "ROC",
               search = "grid",
               iter = 10,#tuneGrid = data.frame(mtry=4), #expand.grid(.mtry=c(1:8)),
               maxdepth = 5,
               nu = 5,
               # ntree = 100,
               trControl = trainControl(method = "repeatedcv", # cross-validation,
                                        number= 1,
                                        repeats = 1,
                                        summaryFunction = twoClassSummary,
                                        classProbs = TRUE
                                       )
              )

fit.RF

preds = predict(fit.RF, test)

table(test.Y)
confusionMatrix(preds, test.Y, positive="True", mode="everything")

fit.RF.roc = roc(test.Y,
                 predict(fit.RF,test, type="prob")[,1],
                 levels=rev(levels(test.Y)))
fit.RF.roc

plot(fit.RF.roc, 
     print.thres = c(.5), 
     type = "S",
     print.thres.pattern = "%.3f (Spec = %.2f, Sens = %.2f)",
     print.thres.cex = .8,
     legacy.axes=TRUE)


```


SVM
```{r}
library(caret)
library(pROC)
set.seed(123)

fit.svm = train(
               Class ~., # define the model
               data = train, # data
               method = "svmRadial",
               metric = "ROC",
               tuneLength=10,
               preProc = c("center", "scale"),
               trControl = trainControl(method = "repeatedcv", # cross-validation
                                        number= 10,
                                        repeats = 5,
                                        summaryFunction = twoClassSummary,
                                        classProbs = TRUE
                                       )
              )

getTrainPerf(fit.svm)

print(fit.svm)

preds = predict(fit.svm, test)
confusionMatrix(preds, test.Y, positive="True", mode="everything")

fit.svm.roc = roc(test.Y,
                 predict(fit.svm,test, type="prob")[,1],
                 levels=rev(levels(test.Y)))
fit.svm.roc

plot(fit.svm.roc, 
     print.thres = c(.5), 
     type = "S",
     print.thres.pattern = "%.3f (Spec = %.2f, Sens = %.2f)",
     print.thres.cex = .8,
     legacy.axes=TRUE)


```

Random Forest with optimized threshold
```{r}
library(caret)
library(randomForest)
set.seed(123)
## Now customize model to find best threshold

## Get the model code for the original random forest method:

thresh_code <- getModelInfo("rf", regex = FALSE)[[1]]
thresh_code$type <- c("Classification")
## Add the threshold as another tuning parameter
thresh_code$parameters <- data.frame(parameter = c("mtry", "threshold"),
                                     class = c("numeric", "numeric"),
                                     label = c("#Randomly Selected Predictors",
                                               "Probability Cutoff"))
## The default tuning grid code:
thresh_code$grid <- function(x, y, len = NULL, search = "grid") {
  p <- ncol(x)
  if(search == "grid") {
    grid <- expand.grid(mtry = floor(sqrt(p)), 
                        threshold = seq(.01, .99, length = len))
    } else {
      grid <- expand.grid(mtry = sample(1:p, size = len),
                          threshold = runif(1, 0, size = len))
      }
  grid
  }

## Here we fit a single random forest model (with a fixed mtry)
## and loop over the threshold values to get predictions from the same
## randomForest model.
thresh_code$loop = function(grid) {   
  library(plyr)
  loop <- ddply(grid, c("mtry"),
                function(x) c(threshold = max(x$threshold)))
  submodels <- vector(mode = "list", length = nrow(loop))
  for(i in seq(along = loop$threshold)) {
    index <- which(grid$mtry == loop$mtry[i])
    cuts <- grid[index, "threshold"] 
    submodels[[i]] <- data.frame(threshold = cuts[cuts != loop$threshold[i]])
    }    
  list(loop = loop, submodels = submodels)
  }

## Fit the model independent of the threshold parameter
thresh_code$fit = function(x, y, wts, param, lev, last, classProbs, ...) { 
  if(length(levels(y)) != 2)
    stop("This works only for 2-class problems")
  randomForest(x, y, mtry = param$mtry, ...)
  }

## Now get a probability prediction and use different thresholds to
## get the predicted class
thresh_code$predict = function(modelFit, newdata, submodels = NULL) {
  class1Prob <- predict(modelFit, 
                        newdata, 
                        type = "prob")[, modelFit$obsLevels[1]]
  ## Raise the threshold for class #1 and a higher level of
  ## evidence is needed to call it class 1 so it should 
  ## decrease sensitivity and increase specificity
  out <- ifelse(class1Prob >= modelFit$tuneValue$threshold,
                modelFit$obsLevels[1], 
                modelFit$obsLevels[2])
  if(!is.null(submodels)) {
    tmp2 <- out
    out <- vector(mode = "list", length = length(submodels$threshold))
    out[[1]] <- tmp2
    for(i in seq(along = submodels$threshold)) {
      out[[i+1]] <- ifelse(class1Prob >= submodels$threshold[[i]],
                           modelFit$obsLevels[1], 
                           modelFit$obsLevels[2])
      }
    } 
  out  
  }

## The probabilities are always the same but we have to create
## mulitple versions of the probs to evaluate the data across
## thresholds
thresh_code$prob = function(modelFit, newdata, submodels = NULL) {
  out <- as.data.frame(predict(modelFit, newdata, type = "prob"))
  if(!is.null(submodels)) {
    probs <- out
    out <- vector(mode = "list", length = length(submodels$threshold)+1)
    out <- lapply(out, function(x) probs)
    } 
  out 
}

####################

fourStats <- function (data, lev = levels(data$obs), model = NULL) {
  ## This code will get use the area under the ROC curve and the
  ## sensitivity and specificity values using the current candidate
  ## value of the probability threshold.
  out <- c(twoClassSummary(data, lev = levels(data$obs), model = NULL))
  
  ## The best possible model has sensitivity of 1 and specificity of 1. 
  ## How far are we from that value?
  coords <- matrix(c(1, 1, out["Spec"], out["Sens"]), 
                   ncol = 2, 
                   byrow = TRUE)
  colnames(coords) <- c("Spec", "Sens")
  rownames(coords) <- c("Best", "Current")
  c(out, Dist = dist(coords)[1])
}

```
Use above to fit a model
```{r}
library(randomForest)
library(reshape2)
library(pROC)
set.seed(123)

fit.RF.thresh <- train(
              Class ~., 
              data = train,
              method = thresh_code,
              ## Minimize the distance to the perfect model
              metric = "Dist",
              maximize = FALSE,
              preProc = c("center", "scale"),
              tuneLength = 20,
              ntree = 100,
              trControl = trainControl(method = "repeatedcv",
                                       number=10,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       summaryFunction = fourStats))
fit.RF.thresh
getTrainPerf(fit.RF.thresh)

preds = predict(fit.RF.thresh, test)
confusionMatrix(preds, test.Y, positive="True", mode="everything")

fit.RF.thresh.roc = roc(test.Y,
                        predict(fit.RF.thresh,test, type="prob")[,1],
                        levels=rev(levels(test.Y)))



plot(fit.RF.thresh.roc, 
     print.thres = c(.5), 
     type = "S",
     print.thres.pattern = "%.3f (Spec = %.2f, Sens = %.2f)",
     print.thres.cex = .8,
     legacy.axes=TRUE)

metrics <- fit.RF.thresh$results[, c(2, 4:6)]
metrics <- melt(metrics, id.vars = "threshold", 
                variable.name = "Resampled",
                value.name = "Data")

ggplot(metrics, aes(x = threshold, y = Data, color = Resampled)) + 
  geom_line() + 
  ylab("") + xlab("Probability Cutoff") +
  theme(legend.position = "top")
```


Lasso
```{r}
library(caret)
library(pROC)
set.seed(123)

# fit a lasso model 
fit.lasso = train(
                  Class ~., # define the model
                  data = train, # data
                  method = "glmnet", # use glmnet
                  family="binomial", # logistic regression
                  trControl = trainControl(method = "repeatedcv", # cross-validation,
                                           repeats = 5,
                                           summaryFunction = twoClassSummary,
                                           classProbs = TRUE
                                          ),
                  metric = "ROC", # optimize by ROC
                  tuneGrid=expand.grid(.alpha=1, .lambda=seq(0, 1, by = 0.1)) # grid for lambda search
                  )
# print results
getTrainPerf(fit.lasso)
fit.lasso.roc = roc(test.Y,
                    predict(fit.lasso,test, type="prob")[,1],
                    levels=rev(levels(test.Y)))
fit.lasso.roc
plot(fit.lasso.roc, 
     print.thres = c(.5), 
     type = "S",
     print.thres.pattern = "%.3f (Spec = %.2f, Sens = %.2f)",
     print.thres.cex = .8,
     legacy.axes=TRUE)



```
